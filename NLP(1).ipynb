{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMKGbfqJZzLNkTH4FHJ/BVd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"neYUefGvOPfj","executionInfo":{"status":"ok","timestamp":1722872847093,"user_tz":-330,"elapsed":4505,"user":{"displayName":"HEMA PRIYA V 2022-2026","userId":"10640191303014301185"}}},"outputs":[],"source":["import nltk\n","from collections import Counter"]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","text = \"This is a sample text for demonstrating unigram model probabilities and word frequency.\"\n","tokens = nltk.word_tokenize(text.lower())\n","unigrams = tokens\n","unigram_freq = Counter(unigrams)\n","total_unigrams = len(unigrams)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WlMO3pjeOQbX","executionInfo":{"status":"ok","timestamp":1722872863970,"user_tz":-330,"elapsed":1081,"user":{"displayName":"HEMA PRIYA V 2022-2026","userId":"10640191303014301185"}},"outputId":"42d58038-1cc9-46ec-de8c-e31e10e0bf7d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","source":["unigram_probabilities = {word: count / total_unigrams for word, count in unigram_freq.items()}"],"metadata":{"id":"VE6Srm7QOZXj","executionInfo":{"status":"ok","timestamp":1722872870850,"user_tz":-330,"elapsed":528,"user":{"displayName":"HEMA PRIYA V 2022-2026","userId":"10640191303014301185"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["print(\"Unigram Frequencies:\")\n","for word, freq in unigram_freq.items():\n","    print(f\"{word}: {freq}\")\n","\n","print(\"\\nUnigram Probabilities:\")\n","for word, prob in unigram_probabilities.items():\n","    print(f\"{word}: {prob:.4f}\")\n","\n","# Predict the probability of a given word\n","def predict_word_probability(word):\n","    return unigram_probabilities.get(word, 0.0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XK1l4nPfObO0","executionInfo":{"status":"ok","timestamp":1722872878528,"user_tz":-330,"elapsed":571,"user":{"displayName":"HEMA PRIYA V 2022-2026","userId":"10640191303014301185"}},"outputId":"27617836-ce47-4349-ecf2-0b7e2b28f060"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Unigram Frequencies:\n","this: 1\n","is: 1\n","a: 1\n","sample: 1\n","text: 1\n","for: 1\n","demonstrating: 1\n","unigram: 1\n","model: 1\n","probabilities: 1\n","and: 1\n","word: 1\n","frequency: 1\n",".: 1\n","\n","Unigram Probabilities:\n","this: 0.0714\n","is: 0.0714\n","a: 0.0714\n","sample: 0.0714\n","text: 0.0714\n","for: 0.0714\n","demonstrating: 0.0714\n","unigram: 0.0714\n","model: 0.0714\n","probabilities: 0.0714\n","and: 0.0714\n","word: 0.0714\n","frequency: 0.0714\n",".: 0.0714\n"]}]},{"cell_type":"code","source":["word_to_predict = \"unigram\"\n","print(f\"\\nProbability of '{word_to_predict}': {predict_word_probability(word_to_predict):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BBI9e5e9OdDl","executionInfo":{"status":"ok","timestamp":1722872888620,"user_tz":-330,"elapsed":541,"user":{"displayName":"HEMA PRIYA V 2022-2026","userId":"10640191303014301185"}},"outputId":"3e7bdbab-484c-4b8a-b527-760fd01a91e0"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Probability of 'unigram': 0.0714\n"]}]},{"cell_type":"code","source":["BIGRAM"],"metadata":{"id":"U1eWWOLbOfgj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","from nltk.util import ngrams\n","from collections import Counter, defaultdict\n","text = \"This is a sample text for demonstrating bigram model probabilities and next word prediction.\"\n","tokens = nltk.word_tokenize(text.lower())\n","bigrams = list(ngrams(tokens, 2))\n","bigram_freq = Counter(bigrams)\n","bigram_probabilities = defaultdict(lambda: defaultdict(float))\n","for (w1, w2) in bigrams:\n","    bigram_probabilities[w1][w2] += 1\n","\n","for w1 in bigram_probabilities:\n","    total_count = float(sum(bigram_probabilities[w1].values()))\n","    for w2 in bigram_probabilities[w1]:\n","        bigram_probabilities[w1][w2] /= total_count\n","print(\"Bigram Frequencies:\")\n","for bigram, freq in bigram_freq.items():\n","    print(f\"{bigram}: {freq}\")\n","word_to_predict = \"bigram\"\n","print(f\"\\nNext word predictions for '{word_to_predict}':\", predict_next_word(word_to_predict, 3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":436},"id":"VRRbOkDwOjUt","executionInfo":{"status":"error","timestamp":1722872911191,"user_tz":-330,"elapsed":763,"user":{"displayName":"HEMA PRIYA V 2022-2026","userId":"10640191303014301185"}},"outputId":"a05f0b57-8610-457f-d42f-495161a39cad"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Bigram Frequencies:\n","('this', 'is'): 1\n","('is', 'a'): 1\n","('a', 'sample'): 1\n","('sample', 'text'): 1\n","('text', 'for'): 1\n","('for', 'demonstrating'): 1\n","('demonstrating', 'bigram'): 1\n","('bigram', 'model'): 1\n","('model', 'probabilities'): 1\n","('probabilities', 'and'): 1\n","('and', 'next'): 1\n","('next', 'word'): 1\n","('word', 'prediction'): 1\n","('prediction', '.'): 1\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'predict_next_word' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-af42a6a71830>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{bigram}: {freq}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mword_to_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bigram\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nNext word predictions for '{word_to_predict}':\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_next_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_to_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'predict_next_word' is not defined"]}]},{"cell_type":"markdown","source":["TRIGRAM"],"metadata":{"id":"cyyDJgcYOtvW"}},{"cell_type":"markdown","source":[],"metadata":{"id":"IIY3hmHQOghl"}},{"cell_type":"code","source":["import nltk\n","from nltk.util import ngrams\n","from collections import Counter, defaultdict\n","\n","text = \"trigram model probabilities and next word prediction.\"\n","\n","tokens = nltk.word_tokenize(text.lower())\n","\n","trigrams = list(ngrams(tokens, 3))\n","trigram_freq = Counter(trigrams)\n","\n","trigram_probabilities = defaultdict(lambda: defaultdict(lambda: 0))\n","for (w1, w2, w3) in trigrams:\n","    trigram_probabilities[(w1, w2)][w3] += 1\n","\n","for (w1, w2) in trigram_probabilities:\n","    total_count = float(sum(trigram_probabilities[(w1, w2)].values()))\n","    for w3 in trigram_probabilities[(w1, w2)]:\n","        trigram_probabilities[(w1, w2)][w3] /= total_count\n","\n","print(\"Trigram Frequencies:\")\n","for trigram, freq in trigram_freq.items():\n","    print(f\"{trigram}: {freq}\")\n","\n","print(\"\\nTrigram Probabilities:\")\n","for (w1, w2), next_words in trigram_probabilities.items():\n","    for w3, prob in next_words.items():\n","        print(f\"P({w3}|{w1} {w2}) = {prob:.4f}\")\n","\n","def predict_next_word(word1, word2, n=1):\n","    next_words = trigram_probabilities[(word1, word2)]\n","    sorted_next_words = sorted(next_words.items(), key=lambda item: item[1], reverse=True)\n","    return [w for w, prob in sorted_next_words[:n]]\n","\n","word1 = \"demonstrating\"\n","word2 = \"trigram\"\n","print(f\"\\nNext word predictions for '{word1} {word2}':\", predict_next_word(word1, word2, 3))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eYBZC9vHOrkj","executionInfo":{"status":"ok","timestamp":1722872940601,"user_tz":-330,"elapsed":510,"user":{"displayName":"HEMA PRIYA V 2022-2026","userId":"10640191303014301185"}},"outputId":"90143051-e796-4c46-ded8-812c5f423253"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Trigram Frequencies:\n","('trigram', 'model', 'probabilities'): 1\n","('model', 'probabilities', 'and'): 1\n","('probabilities', 'and', 'next'): 1\n","('and', 'next', 'word'): 1\n","('next', 'word', 'prediction'): 1\n","('word', 'prediction', '.'): 1\n","\n","Trigram Probabilities:\n","P(probabilities|trigram model) = 1.0000\n","P(and|model probabilities) = 1.0000\n","P(next|probabilities and) = 1.0000\n","P(word|and next) = 1.0000\n","P(prediction|next word) = 1.0000\n","P(.|word prediction) = 1.0000\n","\n","Next word predictions for 'demonstrating trigram': []\n"]}]},{"cell_type":"code","source":["BIGRAM PROBABILITIES"],"metadata":{"id":"HE2GhPnwOyD7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","from nltk.util import ngrams\n","from collections import Counter, defaultdict\n","\n","\n","text = \"demonstrating bigram model probabilities.\"\n","tokens = nltk.word_tokenize(text.lower())\n","\n","bigrams = list(ngrams(tokens, 2))\n","bigram_freq = Counter(bigrams)\n","bigram_probabilities = defaultdict(lambda: defaultdict(float))\n","for (w1, w2) in bigrams:\n","    bigram_probabilities[w1][w2] += 1\n","\n","for w1 in bigram_probabilities:\n","    total_count = float(sum(bigram_probabilities[w1].values()))\n","    for w2 in bigram_probabilities[w1]:\n","        bigram_probabilities[w1][w2] /= total_count\n","\n","print(\"Bigram Frequencies:\")\n","for bigram, freq in bigram_freq.items():\n","    print(f\"{bigram}: {freq}\")\n","\n","print(\"\\nBigram Probabilities:\")\n","for w1, next_words in bigram_probabilities.items():\n","    for w2, prob in next_words.items():\n","        print(f\"P({w2}|{w1}) = {prob:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qDjWpoI2OsHz","executionInfo":{"status":"ok","timestamp":1722873002866,"user_tz":-330,"elapsed":425,"user":{"displayName":"HEMA PRIYA V 2022-2026","userId":"10640191303014301185"}},"outputId":"0d7f3499-9ae3-41dc-c072-12db49c0a60b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Bigram Frequencies:\n","('demonstrating', 'bigram'): 1\n","('bigram', 'model'): 1\n","('model', 'probabilities'): 1\n","('probabilities', '.'): 1\n","\n","Bigram Probabilities:\n","P(bigram|demonstrating) = 1.0000\n","P(model|bigram) = 1.0000\n","P(probabilities|model) = 1.0000\n","P(.|probabilities) = 1.0000\n"]}]},{"cell_type":"markdown","source":["PREDICT NEXT WORD"],"metadata":{"id":"XEA1sKwLO9s_"}},{"cell_type":"code","source":["import nltk\n","from nltk.util import ngrams\n","from collections import Counter, defaultdict\n","\n","text = \"This is a sample text for demonstrating bigram model probabilities and next word prediction.\"\n","\n","tokens = nltk.word_tokenize(text.lower())\n","\n","bigrams = list(ngrams(tokens, 2))\n","bigram_freq = Counter(bigrams)\n","\n","bigram_probabilities = defaultdict(lambda: defaultdict(float))\n","for (w1, w2) in bigrams:\n","    bigram_probabilities[w1][w2] += 1\n","\n","for w1 in bigram_probabilities:\n","    total_count = float(sum(bigram_probabilities[w1].values()))\n","    for w2 in bigram_probabilities[w1]:\n","        bigram_probabilities[w1][w2] /= total_count\n","\n","def predict_next_word(word, n=1):\n","    next_words = bigram_probabilities[word]\n","    sorted_next_words = sorted(next_words.items(), key=lambda item: item[1], reverse=True)\n","    return [w for w, prob in sorted_next_words[:n]]\n","\n","word_to_predict = \"bigram\"\n","print(f\"Next word predictions for '{word_to_predict}':\", predict_next_word(word_to_predict, 3))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PxtQLDfCPBGH","executionInfo":{"status":"ok","timestamp":1722873057568,"user_tz":-330,"elapsed":464,"user":{"displayName":"HEMA PRIYA V 2022-2026","userId":"10640191303014301185"}},"outputId":"fbe79de4-045d-4817-c3a8-f081258b708e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Next word predictions for 'bigram': ['model']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"MbAzdVTxPIp0"},"execution_count":null,"outputs":[]}]}